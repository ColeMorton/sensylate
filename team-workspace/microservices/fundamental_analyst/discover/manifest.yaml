# Fundamental Analyst Discover Manifest
# DASV Phase 1: Data Acquisition and Context Gathering

command:
  name: "fundamental_analyst_discover"
  version: "1.0.0"
  type: "microservice"
  role: "fundamental_analyst"
  action: "discover"
  framework: "DASV"
  description: "Data acquisition and context gathering for fundamental analysis"
  command_file: "/Users/colemorton/Projects/sensylate/team-workspace/microservices/fundamental_analyst/discover.md"

capabilities:
  reads:
    - market_data
    - company_information
    - financial_statements
    - sec_filings
    - economic_indicators
    - yahoo_finance_api
    - cached_data

  produces:
    - structured_discovery_data
    - data_quality_metrics
    - discovery_report
    - cache_updates
    - confidence_scores

dependencies:
  required: []
  optional: []
  external_apis:
    - yahoo_finance
    - sec_edgar
    - fred_economic_data
  conflicts: []

data_schema:
  inputs:
    ticker:
      type: "string"
      required: true
      validation: "uppercase_stock_symbol"
    timeframe:
      type: "string"
      required: false
      default: "5y"
      options: ["3y", "5y", "10y", "full"]
    peer_count:
      type: "integer"
      required: false
      default: 4
      range: [3, 7]
    depth:
      type: "string"
      required: false
      default: "comprehensive"
      options: ["summary", "standard", "comprehensive", "deep-dive"]
    confidence_threshold:
      type: "float"
      required: false
      default: 0.7
      range: [0.6, 0.8]

  outputs:
    discovery_data:
      type: "json"
      location: "/team-workspace/microservices/fundamental_analyst/discover/outputs/"
      filename_pattern: "{ticker}_{YYYYMMDD}_discovery.json"
      schema: "discovery_data_schema_v1"
      metadata_required: true
    cache_data:
      type: "mixed"
      location: "/data/raw/"
      retention_policy: "cache_management_protocol"

collaboration:
  consumption_pattern: "data_driven"
  pre_execution_behavior:
    - "Check cache for existing ticker data"
    - "Validate data freshness requirements"
    - "Initialize quality monitoring systems"
    - "Load economic context data"

  output_sharing: "immediate"
  post_execution_behavior:
    - "Store discovery data with full metadata"
    - "Update cache with new data"
    - "Signal fundamental_analyst_analyze readiness"
    - "Log performance metrics"

  cache_strategy: "aggressive_caching"
  cache_duration: "varies_by_data_type"

  notification_events:
    - event: "discovery_completed"
      notify: ["fundamental_analyst_analyze"]
      payload: ["discovery_data", "confidence_metrics"]
    - event: "data_quality_warning"
      notify: ["fundamental_analyst_validate"]
      payload: ["quality_issues", "confidence_impact"]
    - event: "cache_updated"
      notify: ["team_workspace"]
      payload: ["cache_stats", "data_freshness"]

quality_standards:
  validation_criteria:
    - "All required financial data successfully retrieved"
    - "Data freshness meets minimum requirements"
    - "Company intelligence discovery complete"
    - "Peer group identification successful"
    - "Cache management protocol followed"

  output_requirements:
    - "Structured JSON with complete metadata"
    - "Confidence scores for all data categories"
    - "Quality metrics and validation results"
    - "Clear indication of next phase readiness"
    - "Data lineage and source attribution"

performance_characteristics:
  typical_execution_time: "30s"
  complexity_factors:
    - "Number of data sources required"
    - "Cache hit ratio for ticker"
    - "API response times"
    - "Data validation requirements"

  optimization_strategies:
    - "Aggressive caching with TTL management"
    - "Parallel API calls for different data types"
    - "Incremental data updates when possible"
    - "Rate limiting compliance"

integration_patterns:
  workflow_chains:
    - name: "fundamental_analysis_full"
      position: "first"
      next_service: "fundamental_analyst_analyze"
      trigger: "discovery_completed"

  data_flow:
    incoming:
      - "User request parameters (ticker, timeframe, etc.)"
      - "Cached data from previous discoveries"
      - "Economic context from team workspace"
    outgoing:
      - "Structured discovery data to analyze phase"
      - "Data quality metrics to validate phase"
      - "Cache updates to data management system"

# Service-Level Dependencies
service_dependencies:
  yahoo_finance_service:
    location: "scripts/yahoo_finance_service.py"
    methods: ["info", "history", "financials"]
    rate_limits: "10 requests/minute"
    error_handling: "retry_with_backoff"

  cache_management:
    location: "/data/raw/"
    protocols: ["cache_strategy", "retention_policy"]
    validation: "data_integrity_checks"

# Topic Ownership Configuration
topic_ownership:
  primary_topics:
    - "market-data-discovery"
    - "company-intelligence"
    - "financial-data-acquisition"

  secondary_topics:
    - "data-quality-metrics"
    - "cache-management"

  collaboration_permissions:
    read_access: ["fundamental_analyst_analyze", "fundamental_analyst_validate"]
    write_access: ["fundamental_analyst_discover"]
    coordination_required: []
